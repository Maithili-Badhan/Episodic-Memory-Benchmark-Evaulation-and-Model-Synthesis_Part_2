{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090fbb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:53:36.309856Z",
     "iopub.status.busy": "2025-11-21T10:53:36.309480Z",
     "iopub.status.idle": "2025-11-21T10:53:36.313830Z",
     "shell.execute_reply": "2025-11-21T10:53:36.313015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path to your local repo\n",
    "git_repo_filepath = '/content/episodic-memory-benchmark'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb0824",
   "metadata": {},
   "source": [
    "### Loading books (unchanged — uses existing generation wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18707aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:53:36.318719Z",
     "iopub.status.busy": "2025-11-21T10:53:36.318327Z",
     "iopub.status.idle": "2025-11-21T10:54:06.773400Z",
     "shell.execute_reply": "2025-11-21T10:54:06.772106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, 33.70% remaining with issues (674/2000), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199, 211, 223, 224, 225, 230, 234, 241, 245, 248, 250, 251, 252, 260, 266, 275, 277, 278, 279, 281, 282, 283, 285, 286, 293, 294, 297, 301, 305, 308, 311, 314, 315, 317, 319, 320, 324, 325, 327, 328, 329, 330, 331, 333, 334, 337, 339, 341, 344, 345, 349, 353, 355, 362, 365, 372, 376, 377, 378, 389, 395, 398, 400, 401, 407, 408, 411, 414, 415, 420, 423, 427, 431, 432, 433, 442, 443, 447, 451, 453, 454, 455, 462, 468, 470, 472, 473, 479, 481, 486, 487, 491, 494, 495, 498, 499, 500, 501, 503, 504, 505, 506, 508, 511, 512, 515, 516, 518, 521, 525, 527, 528, 530, 536, 538, 540, 542, 548, 550, 552, 553, 555, 556, 557, 558, 563, 565, 570, 572, 575, 578, 584, 585, 589, 591, 601, 602, 606, 607, 608, 613, 618, 621, 625, 626, 636, 638, 642, 643, 644, 646, 648, 650, 653, 654, 655, 657, 662, 663, 664, 666, 667, 668, 669, 672, 673, 677, 682, 685, 686, 687, 689, 692, 694, 695, 696, 699, 700, 702, 706, 709, 717, 721, 722, 723, 725, 727, 729, 730, 733, 738, 739, 742, 743, 744, 746, 748, 749, 750, 753, 756, 757, 758, 759, 762, 777, 786, 787, 790, 797, 801, 808, 810, 811, 814, 816, 817, 821, 822, 827, 831, 833, 840, 841, 844, 845, 848, 849, 852, 861, 864, 865, 867, 871, 873, 875, 881, 883, 884, 890, 895, 897, 899, 902, 904, 906, 909, 911, 915, 917, 924, 925, 931, 937, 940, 941, 942, 943, 944, 946, 947, 953, 956, 957, 958, 959, 961, 964, 967, 971, 972, 976, 977, 981, 985, 986, 988, 989, 992, 998, 999, 1003, 1004, 1006, 1009, 1014, 1018, 1019, 1025, 1032, 1038, 1039, 1040, 1041, 1043, 1044, 1052, 1057, 1059, 1060, 1067, 1068, 1069, 1073, 1078, 1083, 1085, 1091, 1106, 1108, 1110, 1113, 1114, 1119, 1121, 1123, 1125, 1128, 1131, 1134, 1141, 1142, 1144, 1151, 1152, 1153, 1158, 1168, 1169, 1170, 1171, 1183, 1187, 1189, 1202, 1207, 1209, 1210, 1214, 1216, 1217, 1221, 1223, 1224, 1227, 1229, 1234, 1242, 1244, 1245, 1246, 1249, 1251, 1253, 1255, 1256, 1257, 1258, 1259, 1261, 1268, 1270, 1274, 1285, 1297, 1300, 1304, 1306, 1308, 1311, 1319, 1320, 1328, 1329, 1330, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1362, 1366, 1367, 1368, 1371, 1373, 1376, 1380, 1383, 1390, 1391, 1393, 1399, 1402, 1405, 1408, 1415, 1418, 1422, 1426, 1427, 1433, 1434, 1437, 1447, 1449, 1450, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1461, 1467, 1468, 1469, 1477, 1480, 1483, 1486, 1490, 1497, 1502, 1503, 1505, 1508, 1511, 1512, 1514, 1515, 1517, 1519, 1520, 1521, 1522, 1523, 1531, 1539, 1540, 1541, 1542, 1544, 1547, 1548, 1551, 1552, 1553, 1554, 1555, 1557, 1558, 1559, 1564, 1565, 1570, 1573, 1576, 1579, 1582, 1589, 1592, 1593, 1594, 1596, 1597, 1598, 1602, 1605, 1608, 1612, 1614, 1615, 1623, 1625, 1626, 1628, 1629, 1630, 1631, 1634, 1637, 1643, 1646, 1650, 1658, 1661, 1662, 1667, 1671, 1672, 1675, 1676, 1683, 1684, 1685, 1686, 1689, 1690, 1694, 1696, 1700, 1712, 1713, 1715, 1717, 1720, 1722, 1723, 1725, 1727, 1728, 1730, 1733, 1735, 1744, 1745, 1747, 1748, 1750, 1756, 1760, 1763, 1766, 1769, 1770, 1772, 1773, 1774, 1777, 1782, 1783, 1792, 1801, 1805, 1807, 1814, 1817, 1825, 1826, 1827, 1832, 1834, 1840, 1843, 1846, 1850, 1855, 1856, 1861, 1864, 1866, 1867, 1869, 1870, 1873, 1874, 1878, 1882, 1886, 1898, 1902, 1906, 1907, 1908, 1910, 1914, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1932, 1934, 1938, 1943, 1944, 1945, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1957, 1959, 1962, 1963, 1964, 1970, 1976, 1978, 1980, 1982, 1984, 1986, 1987, 1989, 1991, 1996, 1998].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1, 16.65% remaining with issues (333/2000), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193, 211, 223, 224, 225, 234, 245, 248, 250, 251, 252, 266, 275, 278, 279, 281, 283, 285, 297, 301, 308, 311, 315, 317, 319, 324, 327, 331, 337, 341, 344, 353, 355, 372, 376, 378, 389, 395, 398, 400, 407, 411, 420, 433, 442, 451, 453, 454, 462, 472, 473, 486, 491, 494, 495, 498, 500, 501, 503, 504, 506, 508, 512, 516, 525, 527, 528, 540, 542, 552, 555, 557, 558, 563, 572, 575, 591, 606, 607, 618, 625, 626, 638, 654, 657, 662, 663, 667, 668, 685, 694, 721, 723, 725, 727, 730, 738, 739, 744, 756, 757, 758, 777, 786, 797, 801, 810, 811, 814, 816, 821, 822, 844, 845, 848, 849, 864, 871, 881, 883, 897, 902, 906, 915, 924, 925, 931, 940, 943, 946, 953, 956, 959, 961, 967, 976, 992, 998, 1006, 1009, 1014, 1025, 1038, 1043, 1044, 1057, 1059, 1060, 1068, 1085, 1106, 1110, 1114, 1121, 1123, 1125, 1128, 1131, 1134, 1142, 1144, 1158, 1168, 1169, 1187, 1209, 1210, 1214, 1216, 1217, 1224, 1234, 1245, 1246, 1249, 1251, 1253, 1256, 1258, 1261, 1268, 1274, 1285, 1297, 1300, 1304, 1308, 1311, 1319, 1329, 1353, 1356, 1357, 1360, 1366, 1368, 1371, 1376, 1380, 1383, 1393, 1399, 1415, 1418, 1426, 1437, 1449, 1450, 1452, 1454, 1456, 1467, 1497, 1502, 1505, 1515, 1519, 1520, 1521, 1523, 1531, 1541, 1547, 1551, 1553, 1554, 1555, 1557, 1558, 1564, 1565, 1573, 1576, 1589, 1594, 1597, 1598, 1608, 1612, 1626, 1628, 1637, 1643, 1661, 1671, 1675, 1683, 1689, 1690, 1694, 1700, 1712, 1717, 1720, 1722, 1725, 1727, 1728, 1730, 1747, 1748, 1760, 1763, 1772, 1783, 1792, 1801, 1807, 1817, 1825, 1826, 1832, 1840, 1846, 1855, 1870, 1878, 1882, 1902, 1910, 1916, 1918, 1919, 1920, 1921, 1924, 1932, 1938, 1945, 1947, 1952, 1959, 1962, 1963, 1964, 1976, 1980, 1982, 1989, 1991, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2, 9.75% remaining with issues (195/2000), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193, 211, 223, 245, 266, 275, 279, 283, 285, 297, 311, 319, 324, 331, 355, 372, 376, 378, 395, 398, 400, 420, 433, 453, 454, 472, 494, 498, 500, 501, 504, 506, 508, 516, 528, 540, 542, 552, 555, 557, 563, 625, 638, 654, 663, 667, 694, 727, 738, 739, 756, 757, 777, 801, 814, 821, 822, 844, 845, 871, 881, 883, 897, 915, 924, 931, 940, 943, 953, 956, 959, 961, 967, 998, 1009, 1025, 1038, 1043, 1044, 1057, 1060, 1068, 1085, 1121, 1123, 1131, 1134, 1142, 1168, 1169, 1214, 1216, 1217, 1249, 1258, 1261, 1285, 1297, 1300, 1304, 1311, 1356, 1357, 1360, 1371, 1376, 1380, 1383, 1393, 1415, 1418, 1426, 1437, 1449, 1450, 1452, 1454, 1456, 1467, 1502, 1505, 1520, 1521, 1523, 1541, 1547, 1553, 1554, 1557, 1564, 1565, 1589, 1597, 1598, 1608, 1628, 1671, 1675, 1683, 1694, 1712, 1717, 1720, 1722, 1725, 1727, 1728, 1730, 1747, 1748, 1760, 1763, 1792, 1807, 1817, 1826, 1832, 1855, 1882, 1918, 1919, 1921, 1924, 1932, 1938, 1945, 1947, 1952, 1959, 1962, 1964, 1976, 1980, 1982, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 3, 6.50% remaining with issues (130/2000), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 376, 395, 398, 453, 472, 498, 501, 506, 508, 516, 528, 540, 542, 552, 555, 563, 638, 694, 727, 738, 739, 757, 777, 801, 814, 822, 871, 883, 897, 924, 940, 956, 959, 961, 967, 1009, 1025, 1038, 1043, 1044, 1060, 1068, 1085, 1121, 1134, 1168, 1169, 1214, 1217, 1258, 1261, 1285, 1297, 1300, 1304, 1311, 1356, 1357, 1371, 1376, 1380, 1393, 1415, 1418, 1426, 1437, 1449, 1450, 1454, 1456, 1467, 1520, 1521, 1523, 1553, 1554, 1564, 1565, 1597, 1598, 1608, 1671, 1675, 1694, 1712, 1717, 1722, 1725, 1727, 1728, 1730, 1748, 1792, 1807, 1817, 1826, 1832, 1855, 1882, 1918, 1919, 1924, 1932, 1945, 1952, 1959, 1962, 1976, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 4, 4.95% remaining with issues (99/2000), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 453, 472, 498, 501, 506, 508, 516, 540, 542, 555, 563, 638, 738, 739, 757, 777, 801, 814, 871, 883, 897, 924, 959, 961, 967, 1009, 1025, 1038, 1043, 1044, 1060, 1121, 1134, 1168, 1217, 1261, 1285, 1297, 1300, 1304, 1356, 1357, 1371, 1376, 1380, 1415, 1418, 1437, 1449, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1564, 1565, 1597, 1671, 1675, 1694, 1712, 1717, 1722, 1725, 1727, 1728, 1730, 1792, 1807, 1826, 1832, 1882, 1918, 1919, 1924, 1945, 1952, 1962, 1976, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 5, 3.85% remaining with issues (77/2000), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 453, 472, 506, 508, 516, 540, 542, 555, 563, 638, 738, 777, 801, 814, 871, 883, 897, 924, 959, 961, 1009, 1038, 1043, 1044, 1060, 1121, 1134, 1217, 1261, 1285, 1304, 1356, 1357, 1371, 1376, 1380, 1415, 1418, 1437, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1564, 1597, 1671, 1675, 1694, 1712, 1722, 1725, 1727, 1728, 1832, 1882, 1918, 1919, 1952, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 6, 3.00% remaining with issues (60/2000), for index: [16, 56, 67, 156, 160, 182, 211, 245, 266, 331, 453, 506, 508, 516, 542, 555, 777, 814, 871, 883, 897, 924, 959, 961, 1009, 1038, 1043, 1044, 1060, 1121, 1134, 1217, 1261, 1285, 1304, 1356, 1371, 1380, 1418, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1597, 1671, 1675, 1694, 1712, 1722, 1725, 1727, 1728, 1832, 1882, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 7, 2.35% remaining with issues (47/2000), for index: [16, 56, 67, 156, 160, 211, 245, 331, 453, 508, 516, 542, 555, 777, 814, 871, 883, 897, 959, 961, 1009, 1038, 1043, 1060, 1134, 1217, 1261, 1285, 1304, 1356, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1675, 1694, 1722, 1725, 1727, 1728, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 8, 2.10% remaining with issues (42/2000), for index: [16, 56, 156, 160, 245, 331, 453, 508, 516, 542, 555, 777, 814, 871, 883, 897, 959, 961, 1009, 1038, 1043, 1060, 1134, 1261, 1285, 1304, 1356, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1722, 1725, 1727, 1728, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At final iteration 9, 1.65% remaining with issues (33/2000), for index: [16, 56, 156, 160, 245, 331, 453, 508, 516, 555, 777, 871, 883, 897, 959, 961, 1009, 1038, 1261, 1285, 1304, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1728, 1919, 1952, 1980].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1M chapter book, only select a subset of the questions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0, 33.70% remaining with issues (674/2000), for index: [11, 13, 16, 19, 20, 23, 25, 30, 33, 42, 44, 45, 47, 48, 50, 51, 56, 59, 62, 63, 67, 69, 70, 71, 79, 80, 85, 86, 88, 93, 96, 106, 109, 122, 125, 127, 128, 130, 136, 138, 143, 144, 146, 147, 148, 149, 150, 152, 155, 156, 160, 162, 163, 166, 169, 172, 175, 177, 178, 180, 181, 182, 185, 189, 193, 197, 199, 211, 223, 224, 225, 230, 234, 241, 245, 248, 250, 251, 252, 260, 266, 275, 277, 278, 279, 281, 282, 283, 285, 286, 293, 294, 297, 301, 305, 308, 311, 314, 315, 317, 319, 320, 324, 325, 327, 328, 329, 330, 331, 333, 334, 337, 339, 341, 344, 345, 349, 353, 355, 362, 365, 372, 376, 377, 378, 389, 395, 398, 400, 401, 407, 408, 411, 414, 415, 420, 423, 427, 431, 432, 433, 442, 443, 447, 451, 453, 454, 455, 462, 468, 470, 472, 473, 479, 481, 486, 487, 491, 494, 495, 498, 499, 500, 501, 503, 504, 505, 506, 508, 511, 512, 515, 516, 518, 521, 525, 527, 528, 530, 536, 538, 540, 542, 548, 550, 552, 553, 555, 556, 557, 558, 563, 565, 570, 572, 575, 578, 584, 585, 589, 591, 601, 602, 606, 607, 608, 613, 618, 621, 625, 626, 636, 638, 642, 643, 644, 646, 648, 650, 653, 654, 655, 657, 662, 663, 664, 666, 667, 668, 669, 672, 673, 677, 682, 685, 686, 687, 689, 692, 694, 695, 696, 699, 700, 702, 706, 709, 717, 721, 722, 723, 725, 727, 729, 730, 733, 738, 739, 742, 743, 744, 746, 748, 749, 750, 753, 756, 757, 758, 759, 762, 777, 786, 787, 790, 797, 801, 808, 810, 811, 814, 816, 817, 821, 822, 827, 831, 833, 840, 841, 844, 845, 848, 849, 852, 861, 864, 865, 867, 871, 873, 875, 881, 883, 884, 890, 895, 897, 899, 902, 904, 906, 909, 911, 915, 917, 924, 925, 931, 937, 940, 941, 942, 943, 944, 946, 947, 953, 956, 957, 958, 959, 961, 964, 967, 971, 972, 976, 977, 981, 985, 986, 988, 989, 992, 998, 999, 1003, 1004, 1006, 1009, 1014, 1018, 1019, 1025, 1032, 1038, 1039, 1040, 1041, 1043, 1044, 1052, 1057, 1059, 1060, 1067, 1068, 1069, 1073, 1078, 1083, 1085, 1091, 1106, 1108, 1110, 1113, 1114, 1119, 1121, 1123, 1125, 1128, 1131, 1134, 1141, 1142, 1144, 1151, 1152, 1153, 1158, 1168, 1169, 1170, 1171, 1183, 1187, 1189, 1202, 1207, 1209, 1210, 1214, 1216, 1217, 1221, 1223, 1224, 1227, 1229, 1234, 1242, 1244, 1245, 1246, 1249, 1251, 1253, 1255, 1256, 1257, 1258, 1259, 1261, 1268, 1270, 1274, 1285, 1297, 1300, 1304, 1306, 1308, 1311, 1319, 1320, 1328, 1329, 1330, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1362, 1366, 1367, 1368, 1371, 1373, 1376, 1380, 1383, 1390, 1391, 1393, 1399, 1402, 1405, 1408, 1415, 1418, 1422, 1426, 1427, 1433, 1434, 1437, 1447, 1449, 1450, 1451, 1452, 1454, 1455, 1456, 1457, 1458, 1461, 1467, 1468, 1469, 1477, 1480, 1483, 1486, 1490, 1497, 1502, 1503, 1505, 1508, 1511, 1512, 1514, 1515, 1517, 1519, 1520, 1521, 1522, 1523, 1531, 1539, 1540, 1541, 1542, 1544, 1547, 1548, 1551, 1552, 1553, 1554, 1555, 1557, 1558, 1559, 1564, 1565, 1570, 1573, 1576, 1579, 1582, 1589, 1592, 1593, 1594, 1596, 1597, 1598, 1602, 1605, 1608, 1612, 1614, 1615, 1623, 1625, 1626, 1628, 1629, 1630, 1631, 1634, 1637, 1643, 1646, 1650, 1658, 1661, 1662, 1667, 1671, 1672, 1675, 1676, 1683, 1684, 1685, 1686, 1689, 1690, 1694, 1696, 1700, 1712, 1713, 1715, 1717, 1720, 1722, 1723, 1725, 1727, 1728, 1730, 1733, 1735, 1744, 1745, 1747, 1748, 1750, 1756, 1760, 1763, 1766, 1769, 1770, 1772, 1773, 1774, 1777, 1782, 1783, 1792, 1801, 1805, 1807, 1814, 1817, 1825, 1826, 1827, 1832, 1834, 1840, 1843, 1846, 1850, 1855, 1856, 1861, 1864, 1866, 1867, 1869, 1870, 1873, 1874, 1878, 1882, 1886, 1898, 1902, 1906, 1907, 1908, 1910, 1914, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1932, 1934, 1938, 1943, 1944, 1945, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1957, 1959, 1962, 1963, 1964, 1970, 1976, 1978, 1980, 1982, 1984, 1986, 1987, 1989, 1991, 1996, 1998].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 1, 16.65% remaining with issues (333/2000), for index: [11, 13, 16, 42, 44, 56, 59, 67, 79, 80, 93, 96, 106, 122, 127, 128, 130, 136, 143, 144, 146, 147, 150, 156, 160, 162, 163, 166, 169, 172, 175, 182, 193, 211, 223, 224, 225, 234, 245, 248, 250, 251, 252, 266, 275, 278, 279, 281, 283, 285, 297, 301, 308, 311, 315, 317, 319, 324, 327, 331, 337, 341, 344, 353, 355, 372, 376, 378, 389, 395, 398, 400, 407, 411, 420, 433, 442, 451, 453, 454, 462, 472, 473, 486, 491, 494, 495, 498, 500, 501, 503, 504, 506, 508, 512, 516, 525, 527, 528, 540, 542, 552, 555, 557, 558, 563, 572, 575, 591, 606, 607, 618, 625, 626, 638, 654, 657, 662, 663, 667, 668, 685, 694, 721, 723, 725, 727, 730, 738, 739, 744, 756, 757, 758, 777, 786, 797, 801, 810, 811, 814, 816, 821, 822, 844, 845, 848, 849, 864, 871, 881, 883, 897, 902, 906, 915, 924, 925, 931, 940, 943, 946, 953, 956, 959, 961, 967, 976, 992, 998, 1006, 1009, 1014, 1025, 1038, 1043, 1044, 1057, 1059, 1060, 1068, 1085, 1106, 1110, 1114, 1121, 1123, 1125, 1128, 1131, 1134, 1142, 1144, 1158, 1168, 1169, 1187, 1209, 1210, 1214, 1216, 1217, 1224, 1234, 1245, 1246, 1249, 1251, 1253, 1256, 1258, 1261, 1268, 1274, 1285, 1297, 1300, 1304, 1308, 1311, 1319, 1329, 1353, 1356, 1357, 1360, 1366, 1368, 1371, 1376, 1380, 1383, 1393, 1399, 1415, 1418, 1426, 1437, 1449, 1450, 1452, 1454, 1456, 1467, 1497, 1502, 1505, 1515, 1519, 1520, 1521, 1523, 1531, 1541, 1547, 1551, 1553, 1554, 1555, 1557, 1558, 1564, 1565, 1573, 1576, 1589, 1594, 1597, 1598, 1608, 1612, 1626, 1628, 1637, 1643, 1661, 1671, 1675, 1683, 1689, 1690, 1694, 1700, 1712, 1717, 1720, 1722, 1725, 1727, 1728, 1730, 1747, 1748, 1760, 1763, 1772, 1783, 1792, 1801, 1807, 1817, 1825, 1826, 1832, 1840, 1846, 1855, 1870, 1878, 1882, 1902, 1910, 1916, 1918, 1919, 1920, 1921, 1924, 1932, 1938, 1945, 1947, 1952, 1959, 1962, 1963, 1964, 1976, 1980, 1982, 1989, 1991, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 2, 9.75% remaining with issues (195/2000), for index: [13, 16, 42, 44, 56, 67, 79, 93, 96, 106, 143, 144, 146, 150, 156, 160, 162, 166, 169, 182, 193, 211, 223, 245, 266, 275, 279, 283, 285, 297, 311, 319, 324, 331, 355, 372, 376, 378, 395, 398, 400, 420, 433, 453, 454, 472, 494, 498, 500, 501, 504, 506, 508, 516, 528, 540, 542, 552, 555, 557, 563, 625, 638, 654, 663, 667, 694, 727, 738, 739, 756, 757, 777, 801, 814, 821, 822, 844, 845, 871, 881, 883, 897, 915, 924, 931, 940, 943, 953, 956, 959, 961, 967, 998, 1009, 1025, 1038, 1043, 1044, 1057, 1060, 1068, 1085, 1121, 1123, 1131, 1134, 1142, 1168, 1169, 1214, 1216, 1217, 1249, 1258, 1261, 1285, 1297, 1300, 1304, 1311, 1356, 1357, 1360, 1371, 1376, 1380, 1383, 1393, 1415, 1418, 1426, 1437, 1449, 1450, 1452, 1454, 1456, 1467, 1502, 1505, 1520, 1521, 1523, 1541, 1547, 1553, 1554, 1557, 1564, 1565, 1589, 1597, 1598, 1608, 1628, 1671, 1675, 1683, 1694, 1712, 1717, 1720, 1722, 1725, 1727, 1728, 1730, 1747, 1748, 1760, 1763, 1792, 1807, 1817, 1826, 1832, 1855, 1882, 1918, 1919, 1921, 1924, 1932, 1938, 1945, 1947, 1952, 1959, 1962, 1964, 1976, 1980, 1982, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 3, 6.50% remaining with issues (130/2000), for index: [16, 42, 44, 56, 67, 93, 96, 106, 143, 144, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 376, 395, 398, 453, 472, 498, 501, 506, 508, 516, 528, 540, 542, 552, 555, 563, 638, 694, 727, 738, 739, 757, 777, 801, 814, 822, 871, 883, 897, 924, 940, 956, 959, 961, 967, 1009, 1025, 1038, 1043, 1044, 1060, 1068, 1085, 1121, 1134, 1168, 1169, 1214, 1217, 1258, 1261, 1285, 1297, 1300, 1304, 1311, 1356, 1357, 1371, 1376, 1380, 1393, 1415, 1418, 1426, 1437, 1449, 1450, 1454, 1456, 1467, 1520, 1521, 1523, 1553, 1554, 1564, 1565, 1597, 1598, 1608, 1671, 1675, 1694, 1712, 1717, 1722, 1725, 1727, 1728, 1730, 1748, 1792, 1807, 1817, 1826, 1832, 1855, 1882, 1918, 1919, 1924, 1932, 1945, 1952, 1959, 1962, 1976, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 4, 4.95% remaining with issues (99/2000), for index: [16, 42, 44, 56, 67, 93, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 453, 472, 498, 501, 506, 508, 516, 540, 542, 555, 563, 638, 738, 739, 757, 777, 801, 814, 871, 883, 897, 924, 959, 961, 967, 1009, 1025, 1038, 1043, 1044, 1060, 1121, 1134, 1168, 1217, 1261, 1285, 1297, 1300, 1304, 1356, 1357, 1371, 1376, 1380, 1415, 1418, 1437, 1449, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1564, 1565, 1597, 1671, 1675, 1694, 1712, 1717, 1722, 1725, 1727, 1728, 1730, 1792, 1807, 1826, 1832, 1882, 1918, 1919, 1924, 1945, 1952, 1962, 1976, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 5, 3.85% remaining with issues (77/2000), for index: [16, 56, 67, 93, 146, 156, 160, 182, 193, 211, 245, 266, 283, 331, 453, 472, 506, 508, 516, 540, 542, 555, 563, 638, 738, 777, 801, 814, 871, 883, 897, 924, 959, 961, 1009, 1038, 1043, 1044, 1060, 1121, 1134, 1217, 1261, 1285, 1304, 1356, 1357, 1371, 1376, 1380, 1415, 1418, 1437, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1564, 1597, 1671, 1675, 1694, 1712, 1722, 1725, 1727, 1728, 1832, 1882, 1918, 1919, 1952, 1980, 1996].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 6, 3.00% remaining with issues (60/2000), for index: [16, 56, 67, 156, 160, 182, 211, 245, 266, 331, 453, 506, 508, 516, 542, 555, 777, 814, 871, 883, 897, 924, 959, 961, 1009, 1038, 1043, 1044, 1060, 1121, 1134, 1217, 1261, 1285, 1304, 1356, 1371, 1380, 1418, 1450, 1454, 1456, 1520, 1521, 1553, 1554, 1597, 1671, 1675, 1694, 1712, 1722, 1725, 1727, 1728, 1832, 1882, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 7, 2.35% remaining with issues (47/2000), for index: [16, 56, 67, 156, 160, 211, 245, 331, 453, 508, 516, 542, 555, 777, 814, 871, 883, 897, 959, 961, 1009, 1038, 1043, 1060, 1134, 1217, 1261, 1285, 1304, 1356, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1675, 1694, 1722, 1725, 1727, 1728, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 8, 2.10% remaining with issues (42/2000), for index: [16, 56, 156, 160, 245, 331, 453, 508, 516, 542, 555, 777, 814, 871, 883, 897, 959, 961, 1009, 1038, 1043, 1060, 1134, 1261, 1285, 1304, 1356, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1722, 1725, 1727, 1728, 1919, 1952, 1980].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At final iteration 9, 1.65% remaining with issues (33/2000), for index: [16, 56, 156, 160, 245, 331, 453, 508, 516, 555, 777, 871, 883, 897, 959, 961, 1009, 1038, 1261, 1285, 1304, 1380, 1418, 1454, 1456, 1520, 1521, 1553, 1671, 1728, 1919, 1952, 1980].\n",
      "itermax reached but some events still did not pass the verification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 1M chapter book, only select a subset of the questions\n",
      "Books loaded (generation wrapper created).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from epbench.src.generation.benchmark_generation_wrapper import BenchmarkGenerationWrapper\n",
    "\n",
    "book_parameters = {'indexing': 'default', 'nb_summaries': 0}\n",
    "data_folder = Path('/content/episodic-memory-benchmark/epbench/data')\n",
    "env_file = Path('/content/episodic-memory-benchmark/.env')\n",
    "\n",
    "# Generation with Claude -- 20 events (kept as-is so benchmark generation is preserved)\n",
    "prompt_parameters = {'nb_events': 20, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_default_20 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)\n",
    "\n",
    "# Generation with Claude -- 200 events\n",
    "prompt_parameters = {'nb_events': 200, 'name_universe': 'default', 'name_styles': 'default', 'seed': 0, 'distribution_events': {'name': 'geometric', 'param': 0.1}}\n",
    "model_parameters = {'model_name': 'claude-3-5-sonnet-20240620', 'max_new_tokens': 4096, 'itermax': 10}\n",
    "benchmark_claude_default_200 = BenchmarkGenerationWrapper(prompt_parameters, model_parameters, book_parameters, data_folder, env_file)\n",
    "\n",
    "print('Books loaded (generation wrapper created).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abe4b8",
   "metadata": {},
   "source": [
    "### Helper: short name mapping (recognizes Qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469aca07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:06.777570Z",
     "iopub.status.busy": "2025-11-21T10:54:06.777074Z",
     "iopub.status.idle": "2025-11-21T10:54:06.784345Z",
     "shell.execute_reply": "2025-11-21T10:54:06.783507Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_short_name_from_model_name(answering_model_name, answering_kind, answering_embedding_chunk):\n",
    "    # lightweight mapper to create short display names\n",
    "    if 'gpt-4o-mini' in answering_model_name:\n",
    "        model_name = 'gpt-4o-mini'\n",
    "    elif 'gpt-4o' in answering_model_name:\n",
    "        model_name = 'gpt-4o'\n",
    "    elif 'claude-3-5-sonnet' in answering_model_name:\n",
    "        model_name = 'cl-3.5-sonnet'\n",
    "    elif 'claude-3-haiku' in answering_model_name:\n",
    "        model_name = 'cl-3-haiku'\n",
    "    elif 'o1-mini' in answering_model_name:\n",
    "        model_name = 'o1-mini'\n",
    "    elif 'llama-3.1' in answering_model_name:\n",
    "        model_name = 'llama-3.1'\n",
    "    elif 'qwen3-vl' in answering_model_name or 'qwen/qwen3' in answering_model_name:\n",
    "        model_name = 'qwen3-vl'\n",
    "    else:\n",
    "        model_name = answering_model_name.split('/')[-1]\n",
    "    \n",
    "    if answering_kind == 'prompting':\n",
    "        output = model_name\n",
    "    elif answering_kind == 'rag':\n",
    "        if answering_embedding_chunk == 'chapter':\n",
    "            output = f\"{model_name} (rag, c)\"\n",
    "        else:\n",
    "            output = f\"{model_name} (rag)\"\n",
    "    elif answering_kind == 'ftuning':\n",
    "        output = f\"{model_name} (ftuning)\"\n",
    "    else:\n",
    "        output = model_name\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fd97a",
   "metadata": {},
   "source": [
    "### Experiments configuration — replaced models with Qwen\n",
    "This list drives `get_precomputed_results` below. I replaced the previous multi-provider list with entries using `qwen/qwen3-vl-8b-thinking`. Keep ftuning entries as placeholders (most hosted OpenRouter endpoints do not support provider-side fine-tuning — you must enable only if you have that feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c77b993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:06.787856Z",
     "iopub.status.busy": "2025-11-21T10:54:06.787589Z",
     "iopub.status.idle": "2025-11-21T10:54:11.023707Z",
     "shell.execute_reply": "2025-11-21T10:54:11.022826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 8 experiments (Qwen entries).\n",
      "Document with 10397 tokens, answer with prompting using with qwen/qwen3-vl-8b-thinking\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Document with 102870 tokens, answer with prompting using with qwen/qwen3-vl-8b-thinking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Document with 10397 tokens, answer with rag using with qwen/qwen3-vl-8b-thinking (paragraph chunks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Document with 10397 tokens, answer with rag using with qwen/qwen3-vl-8b-thinking (chapter chunks)\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 102870 tokens, answer with rag using with qwen/qwen3-vl-8b-thinking (paragraph chunks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 102870 tokens, answer with rag using with qwen/qwen3-vl-8b-thinking (chapter chunks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "[INFO] Skipping automatic fine-tuned model setup for qwen/qwen3-vl-8b-thinking (book_nb_events=20).\n",
      "Document with 10397 tokens, answer with ftuning using with qwen/qwen3-vl-8b-thinking\n",
      "[WARN] Could not initialize OpenAI client to retrieve file id: TypeError(\"Client.__init__() got an unexpected keyword argument 'proxies'\"). Skipping retrieval.\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "[INFO] Skipping automatic fine-tuned model setup for qwen/qwen3-vl-8b-thinking (book_nb_events=200).\n",
      "Document with 102870 tokens, answer with ftuning using with qwen/qwen3-vl-8b-thinking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not initialize OpenAI client to retrieve file id: TypeError(\"Client.__init__() got an unexpected keyword argument 'proxies'\"). Skipping retrieval.\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1b1704e3-7c02-4b10-8e5f-cafe82b379fa\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_nb_events</th>\n",
       "      <th>answering_kind</th>\n",
       "      <th>answering_model_name</th>\n",
       "      <th>answering_embedding_chunk</th>\n",
       "      <th>book_model_name</th>\n",
       "      <th>evaluation_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>prompting</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>prompting</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>rag</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>chapter</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>rag</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>chapter</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>ftuning</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>ftuning</td>\n",
       "      <td>qwen/qwen3-vl-8b-thinking</td>\n",
       "      <td>n/a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>&lt;epbench.src.evaluation.evaluation_wrapper.Eva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1704e3-7c02-4b10-8e5f-cafe82b379fa')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1b1704e3-7c02-4b10-8e5f-cafe82b379fa button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1b1704e3-7c02-4b10-8e5f-cafe82b379fa');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   book_nb_events answering_kind       answering_model_name  \\\n",
       "0              20      prompting  qwen/qwen3-vl-8b-thinking   \n",
       "1             200      prompting  qwen/qwen3-vl-8b-thinking   \n",
       "2              20            rag  qwen/qwen3-vl-8b-thinking   \n",
       "3              20            rag  qwen/qwen3-vl-8b-thinking   \n",
       "4             200            rag  qwen/qwen3-vl-8b-thinking   \n",
       "5             200            rag  qwen/qwen3-vl-8b-thinking   \n",
       "6              20        ftuning  qwen/qwen3-vl-8b-thinking   \n",
       "7             200        ftuning  qwen/qwen3-vl-8b-thinking   \n",
       "\n",
       "  answering_embedding_chunk             book_model_name  \\\n",
       "0                       n/a  claude-3-5-sonnet-20240620   \n",
       "1                       n/a  claude-3-5-sonnet-20240620   \n",
       "2                 paragraph  claude-3-5-sonnet-20240620   \n",
       "3                   chapter  claude-3-5-sonnet-20240620   \n",
       "4                 paragraph  claude-3-5-sonnet-20240620   \n",
       "5                   chapter  claude-3-5-sonnet-20240620   \n",
       "6                       n/a  claude-3-5-sonnet-20240620   \n",
       "7                       n/a  claude-3-5-sonnet-20240620   \n",
       "\n",
       "                                   evaluation_object  \n",
       "0  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "1  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "2  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "3  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "4  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "5  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "6  <epbench.src.evaluation.evaluation_wrapper.Eva...  \n",
       "7  <epbench.src.evaluation.evaluation_wrapper.Eva...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epbench.src.evaluation.precomputed_results import get_precomputed_results\n",
    "\n",
    "experiments = [\n",
    "    # prompting, 20 events\n",
    "    {'book_nb_events': 20,  'answering_kind': 'prompting', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking'},\n",
    "    # prompting, 200 events\n",
    "    {'book_nb_events': 200, 'answering_kind': 'prompting', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking'},\n",
    "    # RAG, paragraph + chapter (placeholders)\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking', 'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 20,  'answering_kind': 'rag', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking', 'answering_embedding_chunk': 'chapter'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking', 'answering_embedding_chunk': 'paragraph'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'rag', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking', 'answering_embedding_chunk': 'chapter'},\n",
    "    # fine-tuning placeholders (do NOT enable unless your provider supports hosted fine-tuning and you have credentials)\n",
    "    {'book_nb_events': 20,  'answering_kind': 'ftuning', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking'},\n",
    "    {'book_nb_events': 200, 'answering_kind': 'ftuning', 'answering_model_name': 'qwen/qwen3-vl-8b-thinking'},\n",
    "]\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    if 'answering_embedding_chunk' not in experiments[i]:\n",
    "        experiments[i]['answering_embedding_chunk'] = 'n/a'\n",
    "    # keep book model name consistent (this is used by some scripts expecting a 'book_model_name')\n",
    "    experiments[i]['book_model_name'] = 'claude-3-5-sonnet-20240620'\n",
    "\n",
    "print(f\"Configured {len(experiments)} experiments (Qwen entries).\")\n",
    "\n",
    "all_benchmarks = {\n",
    "    'benchmark_claude_default_20': benchmark_claude_default_20,\n",
    "    'benchmark_claude_default_200': benchmark_claude_default_200\n",
    "}\n",
    "\n",
    "# Run precomputed-results helper (this will create EvaluationWrapper objects for each experiment)\n",
    "df = get_precomputed_results(experiments, env_file, data_folder, all_benchmarks)\n",
    "df  # show dataframe object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc8f5bc",
   "metadata": {},
   "source": [
    "### If you want to run answering loops directly (prompting / rag / ftuning) using EvaluationWrapper\n",
    "Below are example cells you can run instead of `get_precomputed_results` if you want more direct control. They call `EvaluationWrapper` for the Qwen model.\n",
    "- **Important**: make sure your `env_file` contains correct API keys / provider configs. For OpenRouter-style endpoints you likely need `OPENROUTER_API_KEY` or similar in that `.env` and the underlying `epbench` code must support that provider.\n",
    "- Fine-tuning (`ftuning`) is left as a placeholder and uses `ftuning_need_actual_tune=False` so it won't attempt hosted tuning unless you set those flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aa30f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:11.026890Z",
     "iopub.status.busy": "2025-11-21T10:54:11.026606Z",
     "iopub.status.idle": "2025-11-21T10:54:11.540251Z",
     "shell.execute_reply": "2025-11-21T10:54:11.538802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 10397 tokens, answer with prompting using qwen/qwen3-vl-8b-thinking\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Document with 102870 tokens, answer with prompting using qwen/qwen3-vl-8b-thinking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Prompting experiments finished (Qwen).\n"
     ]
    }
   ],
   "source": [
    "from epbench.src.evaluation.evaluation_wrapper import EvaluationWrapper\n",
    "from epbench.src.evaluation.generator_answers_2_rag import get_top_n\n",
    "\n",
    "# --- Prompting (in-context) ---\n",
    "for my_benchmark in [benchmark_claude_default_20, benchmark_claude_default_200]:\n",
    "    model_name = 'qwen/qwen3-vl-8b-thinking'\n",
    "    answering_parameters = {\n",
    "        'kind': 'prompting',\n",
    "        'model_name': model_name,\n",
    "        'max_new_tokens': 4096,\n",
    "        'sleeping_time': 1,\n",
    "        'policy': 'remove_duplicates'\n",
    "    }\n",
    "    print(f\"Document with {my_benchmark.nb_tokens()} tokens, answer with prompting using {model_name}\")\n",
    "    my_evaluation = EvaluationWrapper(my_benchmark, answering_parameters, data_folder, env_file)\n",
    "\n",
    "print('Prompting experiments finished (Qwen).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be4f2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:11.543670Z",
     "iopub.status.busy": "2025-11-21T10:54:11.543375Z",
     "iopub.status.idle": "2025-11-21T10:54:14.111183Z",
     "shell.execute_reply": "2025-11-21T10:54:14.110211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 10397 tokens, answer with rag using qwen/qwen3-vl-8b-thinking (paragraph)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 10397 tokens, answer with rag using qwen/qwen3-vl-8b-thinking (chapter)\n",
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 102870 tokens, answer with rag using qwen/qwen3-vl-8b-thinking (paragraph)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with 102870 tokens, answer with rag using qwen/qwen3-vl-8b-thinking (chapter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "RAG experiments finished (Qwen).\n"
     ]
    }
   ],
   "source": [
    "# --- RAG experiments (builds on embeddings + retrieval) ---\n",
    "for my_benchmark in [benchmark_claude_default_20, benchmark_claude_default_200]:\n",
    "    for embedding_chunk in ['paragraph', 'chapter']:\n",
    "        model_name = 'qwen/qwen3-vl-8b-thinking'\n",
    "        answering_parameters = {\n",
    "            'kind': 'rag',\n",
    "            'model_name': model_name,\n",
    "            'embedding_chunk': embedding_chunk,\n",
    "            'max_new_tokens': 4096,\n",
    "            'sleeping_time': 0,\n",
    "            'embedding_model': 'text-embedding-3-small',\n",
    "            'embedding_batch_size': 2048,\n",
    "            'top_n': get_top_n(embedding_chunk, my_benchmark),\n",
    "            'policy': 'remove_duplicates'\n",
    "        }\n",
    "        print(f\"Document with {my_benchmark.nb_tokens()} tokens, answer with rag using {model_name} ({embedding_chunk})\")\n",
    "        my_evaluation = EvaluationWrapper(my_benchmark, answering_parameters, data_folder, env_file)\n",
    "\n",
    "print('RAG experiments finished (Qwen).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d313c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:14.114639Z",
     "iopub.status.busy": "2025-11-21T10:54:14.114332Z",
     "iopub.status.idle": "2025-11-21T10:54:14.997850Z",
     "shell.execute_reply": "2025-11-21T10:54:14.995913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Placeholder) Document with 10397 tokens, ftuning using qwen/qwen3-vl-8b-thinking — ftuning disabled by default\n",
      "[WARN] Could not initialize OpenAI client to retrieve file id: TypeError(\"Client.__init__() got an unexpected keyword argument 'proxies'\"). Skipping retrieval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "(Placeholder) Document with 102870 tokens, ftuning using qwen/qwen3-vl-8b-thinking — ftuning disabled by default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not initialize OpenAI client to retrieve file id: TypeError(\"Client.__init__() got an unexpected keyword argument 'proxies'\"). Skipping retrieval.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Requested judge model (env or default): gpt-4o-mini-2024-07-18\n",
      "[WARN] try_init_model_generic failed for 'gpt-4o-mini-2024-07-18': Client.__init__() got an unexpected keyword argument 'proxies'\n",
      "[INFO] Trying benchmark model claude-3-5-sonnet-20240620 as judge fallback\n",
      "[INFO] Initialized ModelsWrapper judge: claude-3-5-sonnet-20240620\n",
      "[INFO] 'groundtruth_items' not found in evaluation outputs — inserting empty lists as placeholder to avoid KeyError downstream.\n",
      "[WARN] column 'predicted_items' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'matching_groundtruth_items_score' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] column 'explanation' missing in df_generated_evaluations — inserting default values.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (13) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (2) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (5) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (7) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (1) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (3) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n",
      "[WARN] nb_gt (4) != nb_gt_alt (0). Proceeding with nb_gt_alt for scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_indexes' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'groundtruth_items' — inserting default empty lists.\n",
      "[WARN] ensure_chrono_columns: missing column 'predicted_items' — inserting default empty lists.\n",
      "Ftuning placeholders executed (no hosted tuning by default).\n"
     ]
    }
   ],
   "source": [
    "# --- Fine-tuning placeholders ---\n",
    "for my_benchmark in [benchmark_claude_default_20, benchmark_claude_default_200]:\n",
    "    model_name = 'qwen/qwen3-vl-8b-thinking'\n",
    "    answering_parameters = {\n",
    "        'kind': 'ftuning',\n",
    "        'model_name': model_name,\n",
    "        'max_new_tokens': 4096,\n",
    "        'sleeping_time': 0,\n",
    "        # The code below will NOT actually perform hosted tuning unless you enable ftuning_need_actual_tune=True\n",
    "        'ftuning_input_data_policy': 'single',\n",
    "        'ftuning_need_upload': False,\n",
    "        'ftuning_need_actual_tune': False,\n",
    "        'batch_size': 'auto',\n",
    "        'learning_rate_multiplier': 'auto',\n",
    "        'n_epochs': 5,\n",
    "        'policy': 'remove_duplicates'\n",
    "    }\n",
    "    print(f\"(Placeholder) Document with {my_benchmark.nb_tokens()} tokens, ftuning using {model_name} — ftuning disabled by default\")\n",
    "    my_evaluation = EvaluationWrapper(my_benchmark, answering_parameters, data_folder, env_file)\n",
    "\n",
    "print('Ftuning placeholders executed (no hosted tuning by default).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce3404",
   "metadata": {},
   "source": [
    "### Analysis / plotting cells (kept as in original notebook)\n",
    "Run these after `df` (the dataframe built earlier) is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabcf349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:54:15.004892Z",
     "iopub.status.busy": "2025-11-21T10:54:15.004413Z",
     "iopub.status.idle": "2025-11-21T10:54:15.227198Z",
     "shell.execute_reply": "2025-11-21T10:54:15.226551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1710f58b-ccc3-41d6-8110-a12e539d4bd0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins_items_correct_answer</th>\n",
       "      <th>count</th>\n",
       "      <th>(prompting, qwen/qwen3-vl-8b-thinking, n/a)</th>\n",
       "      <th>(rag, qwen/qwen3-vl-8b-thinking, paragraph)</th>\n",
       "      <th>(rag, qwen/qwen3-vl-8b-thinking, chapter)</th>\n",
       "      <th>(ftuning, qwen/qwen3-vl-8b-thinking, n/a)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00±0.00</td>\n",
       "      <td>1.00±0.00</td>\n",
       "      <td>1.00±0.00</td>\n",
       "      <td>1.00±0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6+</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "      <td>0.00±0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1710f58b-ccc3-41d6-8110-a12e539d4bd0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1710f58b-ccc3-41d6-8110-a12e539d4bd0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1710f58b-ccc3-41d6-8110-a12e539d4bd0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  bins_items_correct_answer  count  \\\n",
       "0                         0      8   \n",
       "1                         1      6   \n",
       "2                         2      2   \n",
       "3                       3-5     11   \n",
       "4                        6+      6   \n",
       "\n",
       "  (prompting, qwen/qwen3-vl-8b-thinking, n/a)  \\\n",
       "0                                   1.00±0.00   \n",
       "1                                   0.00±0.00   \n",
       "2                                   0.00±0.00   \n",
       "3                                   0.00±0.00   \n",
       "4                                   0.00±0.00   \n",
       "\n",
       "  (rag, qwen/qwen3-vl-8b-thinking, paragraph)  \\\n",
       "0                                   1.00±0.00   \n",
       "1                                   0.00±0.00   \n",
       "2                                   0.00±0.00   \n",
       "3                                   0.00±0.00   \n",
       "4                                   0.00±0.00   \n",
       "\n",
       "  (rag, qwen/qwen3-vl-8b-thinking, chapter)  \\\n",
       "0                                 1.00±0.00   \n",
       "1                                 0.00±0.00   \n",
       "2                                 0.00±0.00   \n",
       "3                                 0.00±0.00   \n",
       "4                                 0.00±0.00   \n",
       "\n",
       "  (ftuning, qwen/qwen3-vl-8b-thinking, n/a)  \n",
       "0                                 1.00±0.00  \n",
       "1                                 0.00±0.00  \n",
       "2                                 0.00±0.00  \n",
       "3                                 0.00±0.00  \n",
       "4                                 0.00±0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from epbench.src.results.average_groups import extract_groups\n",
    "nb_events = 200\n",
    "relative_to = ['get', 'bins_items_correct_answer']\n",
    "df_results = extract_groups(df, nb_events, relative_to)\n",
    "df_results = df_results[df_results['get'] == 'all'].drop('get', axis = 1)\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e0a27",
   "metadata": {},
   "source": [
    "### Notes / next steps\n",
    "- If the notebook UI still shows old content after you edited the raw JSON, **restart kernel and clear outputs**, then re-run the notebook top→bottom.\n",
    "- For OpenRouter / open-source-hosted Qwen endpoints: ensure your `.env` contains the proper variables expected by the `epbench` code (check `epbench` auth/provider wrappers). Many community endpoints require different env var names; inspect `epbench` provider code if you need to change key names.\n",
    "- Fine-tuning: provider dependent. Most public endpoints (OpenRouter) do not offer the same hosted fine-tuning mechanics as OpenAI; treat ftuning entries as placeholders unless you have a provider-specific API and the `epbench` wrapper supports it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
